{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1753\n",
      "Test 500\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import pprint\n",
    "import bayes\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def import_texts(category, paths):\n",
    "    data = []\n",
    "    for path in paths:\n",
    "        if \"LICENSE.txt\" in path:\n",
    "            continue\n",
    "        \n",
    "        with open(path, \"r\") as f:\n",
    "            s = f.read().split(\"\\n\")\n",
    "            s = \"\\n\".join(s[2:]) # テキストだけ抽出\n",
    "        \n",
    "        data.append({\n",
    "            \"label\": category,\n",
    "            \"text\": s\n",
    "        })\n",
    "    return data\n",
    "\n",
    "peachy = glob.glob(\"./text/peachy/*.txt\")\n",
    "livedoor = glob.glob(\"./text/livedoor-homme/*.txt\")\n",
    "sports = glob.glob(\"./text/sports-watch/*.txt\")\n",
    "\n",
    "dataset = []\n",
    "dataset += import_texts(\"peachy\", peachy)\n",
    "dataset += import_texts(\"livedoor\", livedoor)\n",
    "dataset += import_texts(\"sports\", sports)\n",
    "random.shuffle(dataset)\n",
    "\n",
    "test_count = 500\n",
    "test_data = pd.DataFrame(dataset[:test_count]) \n",
    "train_data = pd.DataFrame(dataset[test_count:])\n",
    "\n",
    "print(\"Train\", len(train_data))\n",
    "print(\"Test\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>livedoor</td>\n",
       "      <td>「転職できる力」養成講座　その5 ： 『東大卒でも赤字社員 中卒でも黒字社員』\\n今話題のビ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>錦織の敗戦に「立派」「力の差あった」など様々な反応  \\n　25日、テニス全豪オープン（メル...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peachy</td>\n",
       "      <td>映画のセリフに学ぶ！ストレスフリーな「スローラブ」のススメ\\n最近、じわじわと「スローラブ」...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>サッカー米国女子代表が生出演も、訊くべき話は何一つ訊かず……\\n4月1日、ユアテックスタジア...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peachy</td>\n",
       "      <td>今一番飲みたい、オーストラリアワインで華やかな香りを\\n　ワインはフランスとイタリア産だけで...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>sports</td>\n",
       "      <td>【Sports Watch】巨人1位の澤村、涙の理由\\n中央大学のエースとして活躍し、201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>peachy</td>\n",
       "      <td>2010年こそ自分に合った仕事で、新しいワタシに！　転職は「お仕事コンシェルジュ」におまかせ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>livedoor</td>\n",
       "      <td>【力説自動車.web】第1回：クルマ離れなんてウソ！ 震災時こそクルマを！\\n自動車評論家の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>sports</td>\n",
       "      <td>【Sports Watch】中畑氏「今回ほど頭にきたことはありません」\\n26日発売の「週刊...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>livedoor</td>\n",
       "      <td>SHIPSが伝授、ワンランク上を行くスーツの着こなし方 【新生活特集】\\nスーツは、オトコの...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "0    livedoor  「転職できる力」養成講座　その5 ： 『東大卒でも赤字社員 中卒でも黒字社員』\\n今話題のビ...\n",
       "1      sports  錦織の敗戦に「立派」「力の差あった」など様々な反応  \\n　25日、テニス全豪オープン（メル...\n",
       "2      peachy  映画のセリフに学ぶ！ストレスフリーな「スローラブ」のススメ\\n最近、じわじわと「スローラブ」...\n",
       "3      sports  サッカー米国女子代表が生出演も、訊くべき話は何一つ訊かず……\\n4月1日、ユアテックスタジア...\n",
       "4      peachy  今一番飲みたい、オーストラリアワインで華やかな香りを\\n　ワインはフランスとイタリア産だけで...\n",
       "..        ...                                                ...\n",
       "495    sports  【Sports Watch】巨人1位の澤村、涙の理由\\n中央大学のエースとして活躍し、201...\n",
       "496    peachy  2010年こそ自分に合った仕事で、新しいワタシに！　転職は「お仕事コンシェルジュ」におまかせ...\n",
       "497  livedoor  【力説自動車.web】第1回：クルマ離れなんてウソ！ 震災時こそクルマを！\\n自動車評論家の...\n",
       "498    sports  【Sports Watch】中畑氏「今回ほど頭にきたことはありません」\\n26日発売の「週刊...\n",
       "499  livedoor  SHIPSが伝授、ワンランク上を行くスーツの着こなし方 【新生活特集】\\nスーツは、オトコの...\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(1)\n",
    "X = rng.randint(5, size=(6, 100))\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "clf = ComplementNB()\n",
    "clf.fit(X, y)\n",
    "ComplementNB()\n",
    "print(clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 0, 1, 3, 0, 0, 1, 4, 4, 1, 2, 4, 2, 4, 3, 4, 2, 4, 2, 4, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 4, 1, 0, 0, 3, 2, 1, 0, 3, 1, 1, 3, 4, 0, 1,\n",
       "        3, 4, 2, 4, 0, 3, 1, 2, 0, 4, 1, 2, 2, 1, 0, 1, 3, 4, 3, 1, 3, 0,\n",
       "        0, 2, 2, 1, 3, 4, 2, 0, 0, 1, 1, 3, 0, 0, 4, 2, 4, 3, 3, 0, 3, 4,\n",
       "        3, 4, 4, 4, 1, 0, 4, 2, 0, 2, 4, 1],\n",
       "       [1, 0, 2, 4, 4, 0, 4, 1, 4, 1, 0, 2, 3, 1, 2, 4, 4, 2, 2, 0, 1, 2,\n",
       "        2, 0, 1, 2, 4, 0, 1, 2, 1, 4, 2, 0, 0, 1, 0, 1, 3, 1, 1, 4, 4, 3,\n",
       "        0, 3, 0, 3, 1, 2, 4, 0, 0, 3, 1, 1, 0, 0, 4, 2, 3, 4, 2, 0, 3, 3,\n",
       "        1, 2, 4, 3, 0, 0, 4, 2, 4, 2, 0, 3, 0, 0, 4, 2, 1, 0, 4, 3, 0, 1,\n",
       "        2, 4, 4, 3, 3, 3, 3, 2, 3, 3, 4, 3],\n",
       "       [2, 4, 4, 0, 3, 3, 0, 3, 1, 0, 2, 2, 2, 0, 2, 1, 4, 0, 4, 4, 1, 3,\n",
       "        1, 4, 1, 2, 1, 0, 0, 2, 4, 1, 0, 0, 3, 1, 0, 4, 3, 2, 3, 4, 4, 3,\n",
       "        0, 0, 0, 4, 1, 4, 1, 2, 2, 4, 3, 4, 4, 0, 3, 2, 4, 3, 4, 2, 3, 0,\n",
       "        2, 1, 3, 2, 0, 1, 4, 1, 3, 3, 1, 2, 0, 2, 4, 0, 2, 4, 3, 4, 3, 0,\n",
       "        4, 2, 2, 4, 1, 2, 1, 1, 1, 0, 4, 4],\n",
       "       [2, 2, 3, 1, 4, 0, 0, 3, 2, 4, 1, 3, 1, 1, 2, 4, 0, 3, 0, 4, 2, 3,\n",
       "        1, 1, 4, 4, 0, 2, 1, 3, 0, 1, 0, 2, 2, 4, 3, 2, 2, 2, 0, 2, 0, 4,\n",
       "        1, 0, 2, 3, 0, 4, 3, 3, 3, 0, 3, 1, 2, 0, 1, 4, 2, 3, 4, 4, 2, 1,\n",
       "        2, 0, 3, 3, 2, 0, 0, 0, 0, 2, 4, 0, 4, 1, 2, 1, 2, 4, 1, 3, 1, 1,\n",
       "        2, 4, 1, 0, 2, 1, 2, 0, 0, 3, 4, 1],\n",
       "       [0, 4, 0, 3, 2, 4, 3, 2, 4, 2, 4, 0, 0, 4, 2, 2, 4, 2, 3, 0, 0, 4,\n",
       "        3, 4, 3, 3, 4, 0, 3, 1, 4, 4, 3, 2, 2, 2, 2, 2, 0, 2, 1, 2, 3, 0,\n",
       "        0, 1, 1, 3, 3, 3, 1, 3, 3, 3, 1, 3, 0, 4, 0, 2, 4, 4, 2, 0, 3, 2,\n",
       "        4, 0, 4, 2, 3, 4, 2, 4, 1, 3, 4, 3, 0, 3, 0, 4, 3, 0, 3, 1, 4, 4,\n",
       "        2, 2, 4, 2, 1, 2, 3, 1, 3, 3, 0, 4],\n",
       "       [3, 3, 3, 3, 0, 2, 3, 1, 3, 2, 3, 2, 2, 0, 4, 0, 1, 3, 0, 0, 0, 1,\n",
       "        2, 4, 4, 2, 0, 1, 0, 0, 2, 4, 3, 0, 2, 1, 3, 3, 1, 4, 4, 4, 0, 1,\n",
       "        0, 1, 2, 2, 4, 2, 4, 0, 2, 4, 4, 1, 1, 1, 1, 4, 3, 4, 1, 1, 1, 2,\n",
       "        4, 3, 2, 3, 3, 2, 3, 0, 2, 0, 1, 0, 0, 3, 4, 0, 0, 0, 0, 1, 0, 1,\n",
       "        3, 3, 4, 0, 1, 0, 3, 2, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
